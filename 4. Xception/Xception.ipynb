{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import the necessary libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport PIL\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport random\nfrom tqdm import tqdm\nimport tensorflow_addons as tfa\nimport random\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\npd.set_option(\"display.max_columns\", None)\n\nprint(\"Done\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-17T16:17:44.890326Z","iopub.execute_input":"2022-04-17T16:17:44.890796Z","iopub.status.idle":"2022-04-17T16:17:44.899754Z","shell.execute_reply.started":"2022-04-17T16:17:44.890752Z","shell.execute_reply":"2022-04-17T16:17:44.898578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's explore the data.\nHow many images are in the datset, the labels and their frequencies.","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/plant-pathology-2021-fgvc8/train.csv')\nprint(len(train))\nprint(train.columns)\nprint(train['labels'].value_counts())\nprint(train['labels'].value_counts().plot.bar())","metadata":{"execution":{"iopub.status.busy":"2022-04-17T16:17:44.902099Z","iopub.execute_input":"2022-04-17T16:17:44.902865Z","iopub.status.idle":"2022-04-17T16:17:45.146537Z","shell.execute_reply.started":"2022-04-17T16:17:44.902812Z","shell.execute_reply":"2022-04-17T16:17:45.145534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['labels'] = train['labels'].apply(lambda string: string.split(' '))\ntrain","metadata":{"execution":{"iopub.status.busy":"2022-04-17T16:17:45.149491Z","iopub.execute_input":"2022-04-17T16:17:45.149838Z","iopub.status.idle":"2022-04-17T16:17:45.1789Z","shell.execute_reply.started":"2022-04-17T16:17:45.149805Z","shell.execute_reply":"2022-04-17T16:17:45.177869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First I convert the labels representation into **one hot encoded format** using MultilabelBinarizer from sklearn. Now we can see and plot the frequencies of each label. ","metadata":{}},{"cell_type":"code","source":"s = list(train['labels'])\nmlb = MultiLabelBinarizer()\ntrainx = pd.DataFrame(mlb.fit_transform(s), columns=mlb.classes_, index=train.index)\nprint(trainx.columns)\nprint(trainx.sum())\n\nlabels = list(trainx.sum().keys())\nprint(labels)\nlabel_counts = trainx.sum().values.tolist()\n\nfig, ax = plt.subplots(1,1, figsize=(20,6))\n\nsns.barplot(x= labels, y= label_counts, ax=ax)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T16:17:45.181428Z","iopub.execute_input":"2022-04-17T16:17:45.181758Z","iopub.status.idle":"2022-04-17T16:17:45.39063Z","shell.execute_reply.started":"2022-04-17T16:17:45.181725Z","shell.execute_reply":"2022-04-17T16:17:45.389082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Let's view some of the images","metadata":{}},{"cell_type":"code","source":"fig1 = plt.figure(figsize=(26,10))\n\nfor i in range(1, 13):\n    \n    rand =  random.randrange(1, 18000)\n    sample = os.path.join('../input/plant-pathology-2021-fgvc8/train_images/', train['image'][rand])\n    \n    img = PIL.Image.open(sample)\n    \n    ax = fig1.add_subplot(4,3,i)\n    ax.imshow(img)\n    \n    title = f\"{train['labels'][rand]}{img.size}\"\n    plt.title(title)\n    \n    fig1.tight_layout()\n","metadata":{"execution":{"iopub.status.busy":"2022-04-17T16:17:45.39249Z","iopub.execute_input":"2022-04-17T16:17:45.392853Z","iopub.status.idle":"2022-04-17T16:17:59.315691Z","shell.execute_reply.started":"2022-04-17T16:17:45.39282Z","shell.execute_reply":"2022-04-17T16:17:59.314512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Imaze Size & Processing\nfrom the titles we can see some random image sizes - (4000, 2672). Larger images are harder to process hence takes much longer to train the CNN. Downsampling all these 18632 images is also a time consuming task. This is I am going to use the resized imaged for this dataset [resized-plant2021](https://www.kaggle.com/ankursingh12/resized-plant2021) by Ankur Singh. He has already downsampled the images into size of 256, 384, 512 & 640px.\n\nThere are 18632 images in the training set. Even after using the downsampled images we cant fit all of the images into memory at once. So I have used the flow_from_dataframe method from keras. This method reads images in batch size from the storage without loading all the images at once and saving us from **GPU Out of Memory (OOM)** issue. ","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv(\"../input/plant-pathology-2021-fgvc8/train.csv\")\n\nprint(\"Done\")","metadata":{"execution":{"iopub.status.busy":"2022-04-17T16:17:59.317173Z","iopub.execute_input":"2022-04-17T16:17:59.317492Z","iopub.status.idle":"2022-04-17T16:17:59.342592Z","shell.execute_reply.started":"2022-04-17T16:17:59.31746Z","shell.execute_reply":"2022-04-17T16:17:59.341543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(rescale=1/255.0,\n                            rotation_range=5,\n                            zoom_range=0.1,\n                            shear_range=0.05,\n                            horizontal_flip=True,\n                            validation_split=0.2)\n\ntrain_generator = datagen.flow_from_dataframe(\n    train,\n    directory='../input/resized-plant2021/img_sz_256',\n    subset='training',\n    x_col='image',\n    y_col='labels',\n    target_size=(224,224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=444\n    )\n\n#'../input/plant-pathology-2021-fgvc8/train_images'\nvalid_generator = datagen.flow_from_dataframe(\n    train,\n    directory='../input/resized-plant2021/img_sz_256',\n    subset='validation',\n    x_col='image',\n    y_col='labels',\n    target_size=(224,224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=444\n    )","metadata":{"execution":{"iopub.status.busy":"2022-04-17T16:17:59.344236Z","iopub.execute_input":"2022-04-17T16:17:59.344594Z","iopub.status.idle":"2022-04-17T16:18:19.236446Z","shell.execute_reply.started":"2022-04-17T16:17:59.344562Z","shell.execute_reply":"2022-04-17T16:18:19.235242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transfer Learning\nTransfer learning is the process of using frozen weights from a large pre-trained model for a downstream task which is in our case classifying leaf diseases. As we can't use internet in this notebook, I will use the dataset of keras's pretrained models containing the weights of 'imagenet'. The output/top layer of a pretrained layer is a dense layer containing number of nodes = number of output classes. All the models here are pre-trained on 'imagenet' hence they have a output/top layer of 1000 nodes. We will have to replace the output/top layer with our own dense layer with 6 nodes (for 6 classes). \n\nI am going to be using **Xception**.\n","metadata":{}},{"cell_type":"code","source":"seed = 1200\ntf.random.set_seed(seed)\n\nweights_path = '../input/keras-pretrained-models/xception_weights_tf_dim_ordering_tf_kernels_notop.h5'\nmodel = keras.applications.Xception(weights=weights_path, include_top=False, input_shape=(224, 224, 3))\n\nprint(model.input)\nprint(model.output)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T16:18:19.237945Z","iopub.execute_input":"2022-04-17T16:18:19.238568Z","iopub.status.idle":"2022-04-17T16:18:22.806454Z","shell.execute_reply.started":"2022-04-17T16:18:19.23852Z","shell.execute_reply":"2022-04-17T16:18:22.805186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Activation, Losses & Metrices\n\nAs this is a multilabel classification problem, we can't use softmax here, hence the sigmoid activation.\n\nBinary crossentropy is used instead of categorical crossentropy. We use categorical cross-entropy in multi-class problems, but for multi-label problems, we use binary cross-entropy. Think of it this way, an image may have multiple labels, and we need the probabilities that each of these labels corresponds to the given image - this can be considered as n independent binary classifiers for the n labels.\n","metadata":{}},{"cell_type":"code","source":"new_model = tf.keras.Sequential([\n    model,\n    keras.layers.GlobalAveragePooling2D(),\n    keras.layers.Dense(6, \n        kernel_initializer=keras.initializers.RandomUniform(seed=seed),\n        bias_initializer=keras.initializers.Zeros(), name='dense_top', activation='sigmoid')\n])\n\n# Freezing the weights\nfor layer in new_model.layers[:-1]:\n    layer.trainable=False\n    \nnew_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-17T16:18:22.807972Z","iopub.execute_input":"2022-04-17T16:18:22.808301Z","iopub.status.idle":"2022-04-17T16:18:23.231767Z","shell.execute_reply.started":"2022-04-17T16:18:22.80826Z","shell.execute_reply":"2022-04-17T16:18:23.230721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\n\nf1 = tfa.metrics.F1Score(num_classes=6,average='macro')\n\nnew_model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy',f1])\ncallbacks = keras.callbacks.EarlyStopping(monitor=f1, patience=4, mode='max', restore_best_weights=True)\nhistory = new_model.fit_generator(generator=train_generator,\n                    validation_data=valid_generator,\n                    epochs=65,\n                    steps_per_epoch=train_generator.samples//256, # = 58\n                    validation_steps=valid_generator.samples//128,\n                    callbacks=callbacks)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-17T16:18:23.233494Z","iopub.execute_input":"2022-04-17T16:18:23.234215Z","iopub.status.idle":"2022-04-17T16:35:26.397611Z","shell.execute_reply.started":"2022-04-17T16:18:23.23416Z","shell.execute_reply":"2022-04-17T16:35:26.393336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission\n\nFor submission I will resize the test images and then predict the labels for them.","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv('../input/plant-pathology-2021-fgvc8/sample_submission.csv')\n\nfor img_name in tqdm(test['image']):\n    path = '../input/plant-pathology-2021-fgvc8/test_images/'+str(img_name)\n    with PIL.Image.open(path) as img:\n        img = img.resize((256,256))\n        img.save(f'./{img_name}')","metadata":{"execution":{"iopub.status.busy":"2022-04-17T16:35:26.398842Z","iopub.status.idle":"2022-04-17T16:35:26.399376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = datagen.flow_from_dataframe(\n    test,\n    directory = './',\n    x_col=\"image\",\n    y_col= None,\n    color_mode=\"rgb\",\n    target_size = (256,256),\n    classes=None,\n    class_mode=None,\n    batch_size=32,\n    shuffle=False,\n    seed=40,\n)\n\npreds = new_model.predict(test_data)\nprint(preds)\npreds = preds.tolist()\n\nindices = []\nfor pred in preds:\n    temp = []\n    for category in pred:\n        if category>=0.3:\n            temp.append(pred.index(category))\n    if temp!=[]:\n        indices.append(temp)\n    else:\n        temp.append(np.argmax(pred))\n        indices.append(temp)\n    \nprint(indices)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T16:35:26.400804Z","iopub.status.idle":"2022-04-17T16:35:26.401323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\nprint(labels)\n\ntestlabels = []\n\n\nfor image in indices:\n    temp = []\n    for i in image:\n        temp.append(str(labels[i]))\n    testlabels.append(' '.join(temp))\n\nprint(testlabels)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-17T16:35:26.40241Z","iopub.status.idle":"2022-04-17T16:35:26.402915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Remove the resized images from output before submission. if there are any other files present except 'submission.csv' it will throw an error when submitting.","metadata":{}},{"cell_type":"code","source":"delfiles = tf.io.gfile.glob('./*.jpg')\n\nfor file in delfiles:\n    os.remove(file)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T16:35:26.404083Z","iopub.status.idle":"2022-04-17T16:35:26.404672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# accuracy\nplt.figure(figsize=(15,6))\nepoch_list = list(range(1, len(history.history['accuracy']) + 1))\nplt.plot(epoch_list, history.history['accuracy'],label='accuracy')\nplt.plot(epoch_list, history.history['val_accuracy'],label='val_accuracy')\nplt.xlabel('epoches')\nplt.ylabel('accuracy')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-17T16:35:26.406031Z","iopub.status.idle":"2022-04-17T16:35:26.406532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loss\nplt.figure(figsize=(15,6))\nepoch__list = list(range(1,len(history.history['loss'])+1))\nplt.plot(epoch__list, history.history['loss'],label='loss')\nplt.plot(epoch__list, history.history['val_loss'],label='val_loss')\nplt.xlabel('epoches')\nplt.ylabel('loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-17T16:35:26.407883Z","iopub.status.idle":"2022-04-17T16:35:26.408386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# f1  score\nplt.figure(figsize=(15,6))\nepoch__list = list(range(1,len(history.history['f1_score'])+1))\nplt.plot(epoch__list, history.history['f1_score'],label='f1_score')\nplt.plot(epoch__list, history.history['val_f1_score'],label='val_f1_score')\nplt.xlabel('epoches')\nplt.ylabel('f1')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-17T16:35:26.409368Z","iopub.status.idle":"2022-04-17T16:35:26.409875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"arr1 = history.history['loss']\nresult1 = sum(arr1)\nprint(f\"loss_av : {result1 / len(arr1)}\")\n\narr2 = history.history['accuracy']\nresult2 = sum(arr2)\nprint(f\"accuracy_av : {result2 / len(arr2)}\")\n\narr3 = history.history['val_loss']\nresult3 = sum(arr3)\nprint(f\"val_loss_av : {result3 / len(arr3)}\")\n\narr4 = history.history['val_accuracy']\nresult4 = sum(arr4)\nprint(f\"val_accuracy_av : {result4 / len(arr4)}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-17T16:35:26.410792Z","iopub.status.idle":"2022-04-17T16:35:26.411269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv('../input/plant-pathology-2021-fgvc8/sample_submission.csv')\nsub['labels'] = testlabels\nsub\nsub.to_csv('submission.csv', index=False)\nsub","metadata":{"execution":{"iopub.status.busy":"2022-04-17T16:35:26.412235Z","iopub.status.idle":"2022-04-17T16:35:26.412681Z"},"trusted":true},"execution_count":null,"outputs":[]}]}